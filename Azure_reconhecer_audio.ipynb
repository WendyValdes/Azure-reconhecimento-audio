{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2XyvHh43U3hGHOTK3Ie6b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WendyValdes/Azure-reconhecimento-audio/blob/main/Azure_reconhecer_audio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c304d097"
      },
      "source": [
        "## Instalação da Biblioteca Azure Speech SDK\n",
        "\n",
        "Esta célula instala a biblioteca `azure-cognitiveservices-speech`, que é essencial para usar os serviços de Text-to-Speech (TTS) e Speech-to-Text (STT) do Azure. A execução deste comando garante que todas as dependências necessárias estejam disponíveis no ambiente do Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40c2e588",
        "outputId": "ca4f065d-3cab-4ac5-a288-ef657d79407f"
      },
      "source": [
        "!pip install azure-cognitiveservices-speech"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: azure-cognitiveservices-speech in /usr/local/lib/python3.12/dist-packages (1.47.0)\n",
            "Requirement already satisfied: azure-core>=1.31.0 in /usr/local/lib/python3.12/dist-packages (from azure-cognitiveservices-speech) (1.38.0)\n",
            "Requirement already satisfied: requests>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from azure-core>=1.31.0->azure-cognitiveservices-speech) (2.32.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from azure-core>=1.31.0->azure-cognitiveservices-speech) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-cognitiveservices-speech) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-cognitiveservices-speech) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-cognitiveservices-speech) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-cognitiveservices-speech) (2026.1.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "691a5852"
      },
      "source": [
        "## Teste de Text-to-Speech (TTS)\n",
        "\n",
        "Esta célula demonstra como usar o serviço de Text-to-Speech do Azure. Ele configura a chave de assinatura e a região do serviço, define a voz desejada (FranciscaNeural em português do Brasil) e então converte um texto fornecido em áudio, que é reproduzido. Ao final, uma mensagem confirma que o áudio foi gerado com sucesso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06b8f1d1",
        "outputId": "b511300e-b9e1-4951-dd8e-f095706a7277"
      },
      "source": [
        "import azure.cognitiveservices.speech as speechsdk\n",
        "\n",
        "# Configuração do serviço de fala do Azure\n",
        "speech_key = \"suachave\"\n",
        "service_region = \"brazilsouth\"  # Exemplo: \"brazilsouth\", defina a região do seu serviço\n",
        "\n",
        "speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
        "speech_config.speech_synthesis_voice_name = \"pt-BR-FranciscaNeural\"  # Define a voz em português do Brasil\n",
        "\n",
        "# Inicializa o sintetizador de fala\n",
        "speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config)\n",
        "\n",
        "# Texto que será transformado em áudio\n",
        "texto = \"Olá! Esse é um teste do Azure Text-to-Speech.\"\n",
        "\n",
        "# Executa o processo de TTS de forma assíncrona e aguarda a conclusão\n",
        "speech_synthesizer.speak_text_async(texto).get()\n",
        "print(\"Áudio gerado com sucesso!\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Áudio gerado com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3adf78a"
      },
      "source": [
        "## Carregamento de Arquivo de Áudio\n",
        "\n",
        "Esta célula permite carregar um arquivo de áudio do seu computador local para o ambiente do Google Colab. É fundamental para fornecer arquivos para o serviço de Speech-to-Text. Após a execução, o nome do arquivo carregado será armazenado na variável `uploaded_filename` para uso posterior."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "07684095",
        "outputId": "2b6a560a-aa0f-4d9b-8fbe-159a43077b89"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Permite ao usuário fazer upload de arquivos\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Itera sobre os arquivos carregados e imprime seus nomes e tamanhos\n",
        "for fn in uploaded.keys():\n",
        "  print(f'Arquivo enviado pelo usuário: \"{fn}\" com tamanho {len(uploaded[fn])} bytes')\n",
        "  uploaded_filename = fn # Armazena o nome do arquivo carregado para uso futuro"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-42658308-44c2-4665-b813-386d67efbbe2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-42658308-44c2-4665-b813-386d67efbbe2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving PTT-20260119-WA0004.opus to PTT-20260119-WA0004 (1).opus\n",
            "Arquivo enviado pelo usuário: \"PTT-20260119-WA0004 (1).opus\" com tamanho 3181 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58e04191"
      },
      "source": [
        "## Conversão de Áudio (OPUS para WAV)\n",
        "\n",
        "Esta célula é responsável por converter um arquivo de áudio no formato `.opus` (comumente usado por aplicativos de mensagens) para o formato `.wav`, que é o formato preferencial para o serviço de Speech-to-Text do Azure. Ele instala as ferramentas necessárias (ffmpeg) e, em seguida, utiliza `subprocess` para chamar diretamente o `ffmpeg` para realizar a conversão, garantindo que o arquivo de áudio esteja no formato correto para o reconhecimento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ae9f602",
        "outputId": "cac8c21f-d3cd-4140-cdb2-2ecb26b423f3"
      },
      "source": [
        "# Instalar pydub (ainda útil para outras coisas) e ffmpeg para conversão de áudio\n",
        "!pip install pydub\n",
        "!apt-get update && apt-get install -y ffmpeg\n",
        "\n",
        "import os\n",
        "import subprocess # Importa subprocess para chamadas diretas ao ffmpeg\n",
        "\n",
        "# Verifica se o arquivo foi carregado e se é um arquivo .opus\n",
        "if 'uploaded_filename' in globals() and uploaded_filename.endswith('.opus'):\n",
        "    original_opus_file = uploaded_filename\n",
        "    # Sanitiza o nome do arquivo para o comando ffmpeg, evitando problemas com caracteres especiais\n",
        "    simple_opus_file = \"uploaded_audio.opus\"\n",
        "    wav_file = os.path.splitext(simple_opus_file)[0] + '.wav'\n",
        "\n",
        "    # Renomeia o arquivo original para um nome mais simples se ele existir\n",
        "    if os.path.exists(original_opus_file):\n",
        "        os.rename(original_opus_file, simple_opus_file)\n",
        "        print(f\"Arquivo renomeado de '{original_opus_file}' para '{simple_opus_file}'\")\n",
        "    else:\n",
        "        print(f\"Erro: O arquivo original '{original_opus_file}' não foi encontrado.\")\n",
        "        simple_opus_file = None\n",
        "\n",
        "    # Se o arquivo .opus estiver disponível, procede com a conversão\n",
        "    if simple_opus_file:\n",
        "        opus_file_to_convert = simple_opus_file\n",
        "        print(f\"Convertendo {opus_file_to_convert} para {wav_file} usando ffmpeg...\")\n",
        "\n",
        "        try:\n",
        "            # Usa subprocess para chamar ffmpeg diretamente\n",
        "            # -i para entrada, -c:a pcm_s16le para WAV não comprimido, -ar 16000 para taxa de amostragem,\n",
        "            # -ac 1 para mono, -y para sobrescrever o arquivo de saída sem perguntar\n",
        "            command = [\"ffmpeg\", \"-i\", opus_file_to_convert, \"-c:a\", \"pcm_s16le\", \"-ar\", \"16000\", \"-ac\", \"1\", \"-y\", wav_file]\n",
        "            result = subprocess.run(command, capture_output=True, text=True, check=True)\n",
        "            print(\"Conversão concluída com sucesso!\")\n",
        "            print(\"FFmpeg stdout:\", result.stdout)\n",
        "            print(\"FFmpeg stderr:\", result.stderr) # ffmpeg frequentemente imprime o progresso em stderr\n",
        "            converted_filename = wav_file\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"Erro ao converter o arquivo com ffmpeg: {e}\")\n",
        "            print(\"FFmpeg stdout:\", e.stdout)\n",
        "            print(\"FFmpeg stderr:\", e.stderr)\n",
        "            converted_filename = None\n",
        "        except Exception as e:\n",
        "            print(f\"Erro inesperado durante a conversão: {e}\")\n",
        "            converted_filename = None\n",
        "    else:\n",
        "        print(\"Não foi possível processar o arquivo .opus para conversão.\")\n",
        "        converted_filename = None\n",
        "else:\n",
        "    print(\"Nenhum arquivo .opus carregado ou o nome do arquivo não foi encontrado.\")\n",
        "    converted_filename = None"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (0.25.1)\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:3 https://cli.github.com/packages stable InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:5 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 54 not upgraded.\n",
            "Arquivo renomeado de 'PTT-20260119-WA0004 (1).opus' para 'uploaded_audio.opus'\n",
            "Convertendo uploaded_audio.opus para uploaded_audio.wav usando ffmpeg...\n",
            "Conversão concluída com sucesso!\n",
            "FFmpeg stdout: \n",
            "FFmpeg stderr: ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, ogg, from 'uploaded_audio.opus':\n",
            "  Duration: 00:00:01.34, start: 0.002167, bitrate: 18 kb/s\n",
            "  Stream #0:0: Audio: opus, 48000 Hz, mono, fltp\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (opus (native) -> pcm_s16le (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, wav, to 'uploaded_audio.wav':\n",
            "  Metadata:\n",
            "    ISFT            : Lavf58.76.100\n",
            "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 pcm_s16le\n",
            "size=       4kB time=00:00:00.00 bitrate=N/A speed=   0x    \n",
            "size=      42kB time=00:00:01.33 bitrate= 256.7kbits/s speed= 281x    \n",
            "video:0kB audio:42kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.182200%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ce246df"
      },
      "source": [
        "## Reconhecimento de Fala (Speech-to-Text - STT)\n",
        "\n",
        "Esta célula utiliza o serviço de Speech-to-Text do Azure para transcrever áudio de um arquivo `.wav` para texto. Ela configura a chave de assinatura e a região do serviço, e crucialmente, define o idioma de reconhecimento para português do Brasil (`pt-BR`). Ele então usa o nome do arquivo `.wav` convertido para o reconhecimento. O resultado da transcrição é impresso, ou uma mensagem de erro é exibida caso o reconhecimento falhe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d36a3645",
        "outputId": "e3f96c05-a80e-4a09-8217-801bdabde1c3"
      },
      "source": [
        "import azure.cognitiveservices.speech as speechsdk\n",
        "\n",
        "speech_key = \"suaxhave\"\n",
        "service_region = \"brazilsouth\"\n",
        "\n",
        "speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
        "speech_config.speech_recognition_language = \"pt-BR\" # Define o idioma de reconhecimento para português do Brasil\n",
        "\n",
        "# Usa o nome do arquivo convertido, se disponível\n",
        "if 'converted_filename' in globals() and converted_filename:\n",
        "    audio_config = speechsdk.AudioConfig(filename=converted_filename)\n",
        "    print(f\"Usando o arquivo de áudio convertido: {converted_filename}\")\n",
        "elif 'uploaded_filename' in globals() and uploaded_filename.endswith('.wav'):\n",
        "    # Caso um arquivo .wav tenha sido carregado diretamente e não precise de conversão\n",
        "    audio_config = speechsdk.AudioConfig(filename=uploaded_filename)\n",
        "    print(f\"Usando o arquivo de áudio carregado: {uploaded_filename}\")\n",
        "else:\n",
        "    print(\"Erro: Nenhum arquivo de áudio WAV válido disponível para reconhecimento.\")\n",
        "    audio_config = None # Garante que audio_config seja None para evitar erros futuros\n",
        "\n",
        "\n",
        "if audio_config:\n",
        "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
        "\n",
        "    print(\"Reconhecendo fala do arquivo de áudio...\")\n",
        "\n",
        "    result = speech_recognizer.recognize_once_async().get()\n",
        "\n",
        "    if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
        "        print(\"Texto reconhecido: {}\".format(result.text))\n",
        "    elif result.reason == speechsdk.ResultReason.NoMatch:\n",
        "        print(\"Não foi possível reconhecer a fala.\")\n",
        "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
        "        cancellation_details = result.cancellation_details\n",
        "        print(\"Reconhecimento cancelado: {}\".format(cancellation_details.reason))\n",
        "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
        "            print(\"Detalhes do erro: {}\".format(cancellation_details.error_details))\n",
        "else:\n",
        "    print(\"Não foi possível configurar o Speech Recognizer devido à falta de arquivo de áudio válido.\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando o arquivo de áudio convertido: uploaded_audio.wav\n",
            "Reconhecendo fala do arquivo de áudio...\n",
            "Texto reconhecido: Bom dia, tudo bem?\n"
          ]
        }
      ]
    }
  ]
}